SearchStrategy (abstract base class)
│
├── GridSearch (konkrete Implementierung)
├── RandomSearch (weitere Implementierung)
│
└── .search()          -> startet die Optimierung
    .evaluate_config() -> ruft CrossValidator auf

CrossValidator
│
└── .run() -> trainiert das Modell über K Folds mit gegebenen Configs,
              erstellt Dataloaders pro Fold, mittelt Ergebnisse

EarlyStopping
│
└── .should_stop(epoch, metric) -> entscheidet, ob Training beendet wird

DataSplitter
│
└── .split_kfold(dataset, k) -> liefert Fold-Train/Val-Datensplits

DataLoaderFactory
│
└── .create(train_data, val_data, transforms) -> train/val Dataloaders

ModelTrainer
│
└── .train(config, dataloaders, early_stopping) -> Trainingsloop inkl. Balancing

TransformProvider
│
└── .get_transforms() -> gibt train_transform, val_transform zurück


class SearchStrategy:
    def __init__(self, search_space, cross_validator):
        self.search_space = search_space
        self.cross_validator = cross_validator

    def search(self):
        raise NotImplementedError

    def evaluate_config(self, config):
        return self.cross_validator.run(config)


class GridSearch(SearchStrategy):
    def search(self):
        best_score = float('-inf')
        best_config = None
        for config in self._generate_grid():
            score = self.evaluate_config(config)
            if score > best_score:
                best_score = score
                best_config = config
        return best_config, best_score

    def _generate_grid(self):
        # itertools.product oder sklearn ParameterGrid
        pass


class CrossValidator:
    def __init__(self, dataset, trainer, data_splitter, dataloader_factory, transforms, k=5):
        self.dataset = dataset
        self.trainer = trainer
        self.splitter = data_splitter
        self.dataloader_factory = dataloader_factory
        self.transforms = transforms
        self.k = k

    def run(self, config):
        scores = []
        for train_indices, val_indices in self.splitter.split_kfold(self.dataset, self.k):
            train_data, val_data = Subset(self.dataset, train_indices), Subset(self.dataset, val_indices)
            train_loader, val_loader = self.dataloader_factory.create(
                train_data, val_data, self.transforms.get_transforms()
            )
            score = self.trainer.train(config, train_loader, val_loader)
            scores.append(score)
        return sum(scores) / len(scores)


class DataLoaderFactory:
    def create(self, train_data, val_data, transforms):
        return (
            DataLoader(train_data, transform=transforms['train']),
            DataLoader(val_data, transform=transforms['val'])
        )


class EarlyStopping:
    def __init__(self, patience):
        self.patience = patience
        self.counter = 0
        self.best_metric = None

    def should_stop(self, metric):
        if self.best_metric is None or metric > self.best_metric:
            self.best_metric = metric
            self.counter = 0
            return False
        else:
            self.counter += 1
            return self.counter >= self.patience


class ModelTrainer:
    def __init__(self, model_builder, criterion, optimizer_builder, early_stopping, balancing_strategy):
        self.model_builder = model_builder
        self.criterion = criterion
        self.optimizer_builder = optimizer_builder
        self.early_stopping = early_stopping
        self.balancing_strategy = balancing_strategy

    def train(self, config, train_loader, val_loader):
        model = self.model_builder(config)
        optimizer = self.optimizer_builder(model.parameters(), config)
        for epoch in range(config['epochs']):
            self._train_one_epoch(model, train_loader, optimizer)
            val_score = self._validate(model, val_loader)
            if self.early_stopping.should_stop(val_score):
                break
        return val_score



class Experiment:
    def __init__(self, dataset, search_strategy_cls, search_space, trainer_cfg, transforms, k_folds=5):
        self.dataset = dataset
        self.search_strategy_cls = search_strategy_cls
        self.search_space = search_space
        self.trainer_cfg = trainer_cfg
        self.transforms = transforms
        self.k_folds = k_folds

    def run(self):
        splitter = DataSplitter()
        dataloader_factory = DataLoaderFactory()
        early_stopping = EarlyStopping(patience=self.trainer_cfg['patience'])
        trainer = ModelTrainer(**self.trainer_cfg, early_stopping=early_stopping)
        cross_validator = CrossValidator(
            dataset=self.dataset,
            trainer=trainer,
            data_splitter=splitter,
            dataloader_factory=dataloader_factory,
            transforms=self.transforms,
            k=self.k_folds
        )
        strategy = self.search_strategy_cls(
            search_space=self.search_space,
            cross_validator=cross_validator
        )
        return strategy.search()

experiment = Experiment(
    dataset=my_dataset,
    search_strategy_cls=GridSearch,
    search_space=search_space,
    trainer_cfg=trainer_config,
    transforms=TransformProvider(),
    k_folds=5
)
best_config, best_score = experiment.run()



------
Logging
class Logger:
    def log_scalar(self, name: str, value: float, step: int):
        pass

    def log_params(self, params: dict):
        pass

    def log_model(self, model, name: str):
        pass

from torch.utils.tensorboard import SummaryWriter

class TensorBoardLogger(Logger):
    def __init__(self, log_dir):
        self.writer = SummaryWriter(log_dir)

    def log_scalar(self, name, value, step):
        self.writer.add_scalar(name, value, step)

    def log_params(self, params):
        for key, value in params.items():
            self.writer.add_text(f"param/{key}", str(value))

    def log_model(self, model, name):
        self.writer.add_graph(model)

class ModelTrainer:
    def __init__(self, ..., logger: Optional[Logger] = None):
        self.logger = logger

    def train(self, config, train_loader, val_loader):
        ...
        for epoch in range(config['epochs']):
            train_loss = self._train_one_epoch(...)
            val_score = self._validate(...)

            if self.logger:
                self.logger.log_scalar("train/loss", train_loss, epoch)
                self.logger.log_scalar("val/score", val_score, epoch)

            if self.early_stopping.should_stop(val_score):
                break
        return val_score

log_dir = f"runs/config_{hashlib.md5(str(config).encode()).hexdigest()[:8]}"
logger = TensorBoardLogger(log_dir)
trainer = ModelTrainer(..., logger=logger)
