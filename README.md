# Hot Topic Computer Vision - Mouse Grimace Scale
This repository provides a modular training pipeline for Convolutional Neural Networks (CNNs) using PyTorch. The setup is designed for **image classification** tasks with CSV-labeled datasets.

## Directory Structure 

### ðŸ“‚ Data
The `data/` folder contains the datasets used for training and testing. The training pipeline supports **two options** possible structures of the `data/` folder in order to load the dataset correctly:


#### 1ï¸âƒ£ Single Folder (Automatic Split)

If your dataset is **not pre-split** into training and testing sets, simply provide the dataset folder:

```bash
--data_folder_train your_dataset_folder
```

The dataset will be **automatically split** into **80% Training** and **20% Testing** data. The data used for training and testing is stored into `train_labels.csv` and `test_labels.csv` in the `models/[model_name]_[run]/` directory so that later on the test data can be used for further exploration of the model performance.

**Example folder structure:**
```
data/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ data/               # contains image files (e.g., .jpg, .png)
â”‚   â”‚   â”œâ”€â”€ img0.jpg
â”‚   â”‚   â”œâ”€â”€ img1.png
â”‚   â”‚   â””â”€â”€ ...            # more images
â”‚   â””â”€â”€ labels/
â”‚       â””â”€â”€ labels.csv      # CSV file in 'filename,label' format
```

**Example `labels.csv`:**

| filename   | label |
|------------|-------|
| img0.jpg   | 0     |
| img1.png   | 1     |
| ...        | ...   |

---

#### 2ï¸âƒ£ Pre-split Dataset (Separate Train and Test Folders)

If your dataset is **already split** into separate training and testing folders, use:

```bash
--data_folder_train train_folder --data_folder_test test_folder
```

In this case, the pipeline will load **both datasets independently** and **no automatic splitting** will be applied.

**Example folder structure:**
```
data/
â””â”€â”€ dataset/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ data/               # training images
    â”‚   â”‚   â”œâ”€â”€ img0.jpg
    â”‚   â”‚   â”œâ”€â”€ img1.png
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â””â”€â”€ labels/
    â”‚       â””â”€â”€ labels.csv      # 'filename,label' format
    â””â”€â”€ test/
        â”œâ”€â”€ data/               # testing images
        â”‚   â”œâ”€â”€ img100.jpg
        â”‚   â”œâ”€â”€ img101.png
        â”‚   â””â”€â”€ ...
        â””â”€â”€ labels/
            â””â”€â”€ labels.csv      # 'filename,label' format
```

---

> **Note:**  
> - The argument `--data_folder_train` is **always required**  
> - The argument `--data_folder_test` is **optional** if omitted, the training dataset will be automatically split (80/20).

---

### ðŸ“‚ Explainability *(to be implemented)*
This folder will contain scripts for **model explainability and interpretability**:
- Layer-wise Relevance Propagation (LRP)

---
### ðŸ“‚ Models
All trained model checkpoints are saved here. Checkpoints are organized by model name and run ID:

```
models/
â”œâ”€â”€ resnet18_0/                         
â”‚   â”œâ”€â”€ checkpoint_0_resnet18_best.pth  # First best checkpoint (e.g., after epoch 2)
â”‚   â””â”€â”€ checkpoint_1_resnet18_best.pth  # Later found better checkpoint (e.g., after epoch 5)
â”œâ”€â”€ resnet18_1/                         
â”‚   â””â”€â”€ checkpoint_0_resnet18_best.pth  # First best checkpoint (no later improvement)
â”œâ”€â”€ resnet18_2/
â”‚   â”œâ”€â”€ checkpoint_0_resnet18_best.pth  # First best checkpoint
â”‚   â”œâ”€â”€ checkpoint_1_resnet18_best.pth  # Improved checkpoint
â”‚   â””â”€â”€ checkpoint_2_resnet18_best.pth  # Further improved checkpoint
â””â”€â”€ ...                                 # Further training runs
```

---

### Notebooks *(to be implemented)*
This folder is planned for **Jupyter notebooks** to:
- Visualize training results (accuracy/loss curves)
- Plot confusion matrices
- Analyze explainability outputs

---

### Training
Contains the main training script `train.py`, which handles:
- Dataset loading
- Model initialization
- Training and validation loops
- Checkpoint saving


## Example Usage
Go into the root directory `htcv_mgs/` and execute the following command:

```
python train.py --epochs 50 --batch_size 32 --model resnet18 --device cuda --data_folder [foldername_in_data_dir] --pretrained --shuffle
```
