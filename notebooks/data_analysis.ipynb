{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65420d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smalles image: (101, 101)\n",
      "Image sizes that are smaller than 224x224 in one or both dimensions:\n",
      "(220, 220): 2\n",
      "(223, 223): 1\n",
      "(209, 209): 2\n",
      "(190, 190): 2\n",
      "(189, 189): 1\n",
      "(187, 187): 1\n",
      "(197, 197): 2\n",
      "(185, 185): 1\n",
      "(171, 171): 1\n",
      "(195, 195): 1\n",
      "(101, 101): 1\n",
      "(217, 217): 1\n",
      "(217, 266): 1\n",
      "(190, 240): 1\n",
      "(269, 175): 1\n",
      "(263, 205): 1\n",
      "(284, 209): 1\n",
      "(220, 286): 1\n",
      "(244, 213): 1\n",
      "(214, 194): 1\n",
      "(223, 222): 1\n",
      "(214, 265): 1\n",
      "(180, 233): 1\n",
      "(218, 267): 1\n",
      "(185, 269): 1\n",
      "(225, 184): 1\n",
      "(214, 249): 1\n",
      "(225, 203): 1\n",
      "(332, 219): 1\n",
      "(227, 189): 1\n",
      "(213, 252): 1\n",
      "(191, 241): 1\n",
      "(183, 177): 1\n",
      "(169, 227): 1\n",
      "(219, 212): 1\n",
      "(292, 220): 1\n",
      "(217, 278): 1\n",
      "(258, 216): 1\n",
      "(255, 221): 1\n",
      "(212, 192): 1\n",
      "(233, 218): 1\n",
      "(246, 218): 1\n",
      "(215, 199): 1\n",
      "(221, 237): 1\n",
      "(214, 244): 1\n",
      "(207, 229): 1\n",
      "(270, 215): 1\n",
      "(345, 222): 1\n",
      "(205, 248): 1\n",
      "(228, 222): 1\n",
      "(311, 209): 1\n",
      "(262, 189): 1\n",
      "(250, 221): 1\n",
      "(208, 237): 1\n",
      "(222, 272): 1\n",
      "(267, 206): 1\n",
      "(201, 242): 1\n",
      "(257, 221): 1\n",
      "(260, 216): 1\n",
      "(263, 216): 1\n",
      "(218, 252): 1\n",
      "(239, 199): 1\n",
      "(274, 205): 1\n",
      "(250, 205): 1\n",
      "(235, 216): 1\n",
      "(246, 220): 1\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Freun\\Desktop\\htcv_mgs\\data\\MGS_data\\data\"\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "img_paths = list(Path(path).rglob(\"*.jpg\"))\n",
    "dims = {}\n",
    "for img_path in img_paths:\n",
    "    img = Image.open(img_path)\n",
    "    if img.size not in dims:\n",
    "        dims[img.size] = 1\n",
    "    else:\n",
    "        dims[img.size] += 1\n",
    "    img.close()\n",
    "\n",
    "# print(\"Image sizes and their counts:\")\n",
    "# for size, count in dims.items():\n",
    "#     print(f\"{size}: {count}\")\n",
    "    \n",
    "print(f\"Smalles image: {min(dims.keys())}\")\n",
    "\n",
    "print(\"Image sizes that are smaller than 224x224 in one or both dimensions:\")\n",
    "for size, count in dims.items():\n",
    "    if size[0] < 224 or size[1] < 224:\n",
    "        print(f\"{size}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2544a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3406/3406 [01:07<00:00, 50.62it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  [0.49035715 0.43031338 0.36964953]\n",
      "Std:  [0.19827825 0.18251361 0.16136015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34939/34939 [35:59<00:00, 16.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  [0.48938244 0.37434759 0.25759417]\n",
      "Std:  [0.23947592 0.19973618 0.14904125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get normalization statistics for the image dataset \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# labeled dataset\n",
    "mean = np.zeros(3)\n",
    "std = np.zeros(3)\n",
    "\n",
    "path = r\"C:\\Users\\Freun\\Desktop\\htcv_mgs\\data\\MGS_data\\data\"\n",
    "img_paths = list(Path(path).rglob(\"*.jpg\")) + list(Path(path).rglob(\"*.png\"))\n",
    "for img_path in tqdm(img_paths):\n",
    "    img_pil = Image.open(img_path)\n",
    "    img = np.array(img_pil).astype(np.float32) / 255.0\n",
    "    mean += np.mean(img, axis=(0, 1))\n",
    "    std += np.std(img, axis=(0, 1))\n",
    "    img_pil.close()\n",
    "    \n",
    "print(\"Mean: \", mean / len(img_paths))\n",
    "print(\"Std: \", std / len(img_paths))\n",
    "\n",
    "\n",
    "# whole dataset\n",
    "mean = np.zeros(3)\n",
    "std = np.zeros(3)\n",
    "\n",
    "path = r\"C:\\Users\\Freun\\Desktop\\htcv_mgs\\data\\BMv3\"\n",
    "img_paths = list(Path(path).rglob(\"*.jpg\")) + list(Path(path).rglob(\"*.png\"))\n",
    "for img_path in tqdm(img_paths):\n",
    "    img_pil = Image.open(img_path)\n",
    "    img = np.array(img_pil).astype(np.float32) / 255.0\n",
    "    mean += np.mean(img, axis=(0, 1))\n",
    "    std += np.std(img, axis=(0, 1))\n",
    "    img_pil.close()\n",
    "\n",
    "print(\"Mean: \", mean / len(img_paths))\n",
    "print(\"Std: \", std / len(img_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f227d",
   "metadata": {},
   "source": [
    "| Kanal | Mittelwert (Mean) | Standardabweichung (Std) |\n",
    "|-------|-------------------|---------------------------|\n",
    "| R     | 0.49035715        | 0.19827825                |\n",
    "| G     | 0.43031338        | 0.18251361                |\n",
    "| B     | 0.36964953        | 0.16136015                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5462aca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Verarbeitung von 3406 Bildern...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1334/3406 [00:40<00:41, 49.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild aw_20201009_130446211_mouse_l_06576.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1393/3406 [00:42<00:39, 50.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild aw_20201027_091716929_mouse_l_03719.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 1462/3406 [00:43<00:37, 51.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild aw_20201110_092907356_mouse_r_04589.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1497/3406 [00:44<00:37, 50.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild aw_20201124_095320521_mouse_r_00800.jpg zu klein für Stride.\n",
      "Bild aw_20201125_102052423_mouse_r_02808.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 1749/3406 [00:49<00:32, 50.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20210504_133136967_00260.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 1828/3406 [00:50<00:31, 50.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20210507_092114543_10639.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 2033/3406 [00:55<00:27, 50.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20211104_103423371_00772.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2051/3406 [00:55<00:26, 50.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20211107_085213746_00036.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2069/3406 [00:55<00:26, 50.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20211107_085213746_00941.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 2087/3406 [00:56<00:25, 52.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20211107_085213746_02702.jpg zu klein für Stride.\n",
      "Bild jw_20211107_085213746_03420.jpg zu klein für Stride.\n",
      "Bild jw_20211107_085213746_04047.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2100/3406 [00:56<00:24, 53.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20211107_085213746_05472.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2131/3406 [00:57<00:23, 53.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild jw_20211110_071115192_03209.jpg zu klein für Stride.\n",
      "Bild jw_20211110_071115192_03301.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 2199/3406 [00:58<00:24, 49.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_1-9c.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 2210/3406 [00:58<00:23, 51.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_11-14a.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2279/3406 [01:00<00:24, 46.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_12-2a.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2302/3406 [01:00<00:20, 53.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_13-11b.jpg zu klein für Stride.\n",
      "Bild lw_13-11c.jpg zu klein für Stride.\n",
      "Bild lw_13-12a.jpg zu klein für Stride.\n",
      "Bild lw_13-13b.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2321/3406 [01:00<00:19, 55.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_13-17c.jpg zu klein für Stride.\n",
      "Bild lw_13-18b.jpg zu klein für Stride.\n",
      "Bild lw_13-1c.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 2327/3406 [01:01<00:20, 52.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_13-20c.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 2339/3406 [01:01<00:20, 52.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_13-5a.jpg zu klein für Stride.\n",
      "Bild lw_13-7b.jpg zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2352/3406 [01:01<00:19, 54.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_13-9a.jpg zu klein für Stride.\n",
      "Bild lw_16-10c.JPG zu klein für Stride.\n",
      "Bild lw_16-11b.JPG zu klein für Stride.\n",
      "Bild lw_16-11c.JPG zu klein für Stride.\n",
      "Bild lw_16-12b.JPG zu klein für Stride.\n",
      "Bild lw_16-13a.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 2367/3406 [01:01<00:17, 59.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_16-14a.JPG zu klein für Stride.\n",
      "Bild lw_16-15a.JPG zu klein für Stride.\n",
      "Bild lw_16-15b.JPG zu klein für Stride.\n",
      "Bild lw_16-15c.JPG zu klein für Stride.\n",
      "Bild lw_16-16c.JPG zu klein für Stride.\n",
      "Bild lw_16-17b.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 2381/3406 [01:01<00:16, 61.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_16-18b.JPG zu klein für Stride.\n",
      "Bild lw_16-1a.JPG zu klein für Stride.\n",
      "Bild lw_16-1b.JPG zu klein für Stride.\n",
      "Bild lw_16-1c.JPG zu klein für Stride.\n",
      "Bild lw_16-20c.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 2402/3406 [01:02<00:16, 61.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_16-3c.JPG zu klein für Stride.\n",
      "Bild lw_16-5a.JPG zu klein für Stride.\n",
      "Bild lw_16-5b.JPG zu klein für Stride.\n",
      "Bild lw_16-7a.JPG zu klein für Stride.\n",
      "Bild lw_16-7c.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 2415/3406 [01:02<00:17, 55.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_16-8c.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2446/3406 [01:03<00:18, 52.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_19-19b.JPG zu klein für Stride.\n",
      "Bild lw_19-19c.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2478/3406 [01:03<00:16, 55.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_2-11a.JPG zu klein für Stride.\n",
      "Bild lw_2-11b.JPG zu klein für Stride.\n",
      "Bild lw_2-14a.JPG zu klein für Stride.\n",
      "Bild lw_2-14c.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2502/3406 [01:04<00:17, 50.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_2-3b.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 2522/3406 [01:04<00:15, 57.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_3-10b.JPG zu klein für Stride.\n",
      "Bild lw_3-12a.JPG zu klein für Stride.\n",
      "Bild lw_3-13a.JPG zu klein für Stride.\n",
      "Bild lw_3-13c.JPG zu klein für Stride.\n",
      "Bild lw_3-14c.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 2534/3406 [01:04<00:15, 55.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_3-16c.JPG zu klein für Stride.\n",
      "Bild lw_3-17c.JPG zu klein für Stride.\n",
      "Bild lw_3-18a.JPG zu klein für Stride.\n",
      "Bild lw_3-1a.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 2552/3406 [01:05<00:15, 54.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_3-2b.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 2564/3406 [01:05<00:15, 53.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bild lw_3-6b.JPG zu klein für Stride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3406/3406 [01:30<00:00, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmark-Ergebnisse ---\n",
      "Zeit bicubic   : Mittelwert = 2.7382, Std = 2.3283\n",
      "Zeit bilinear  : Mittelwert = 1.3936, Std = 1.2276\n",
      "Zeit stride    : Mittelwert = 0.0558, Std = 0.2297\n",
      "Zeit nearest   : Mittelwert = 0.1169, Std = 0.3198\n",
      "\n",
      "PSNR bilinear  : Mittelwert = 50.8343, Std = 2.2208\n",
      "SSIM bilinear  : Mittelwert = 0.9966, Std = 0.0008\n",
      "PSNR stride    : Mittelwert = 19.9579, Std = 5.8874\n",
      "SSIM stride    : Mittelwert = 0.5692, Std = 0.1375\n",
      "PSNR nearest   : Mittelwert = 40.9852, Std = 2.3799\n",
      "SSIM nearest   : Mittelwert = 0.9675, Std = 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# =============== Pfad zu Bildordner ===============\n",
    "image_folder = r\"C:\\Users\\Freun\\Desktop\\htcv_mgs\\data\\MGS_data\\data\"\n",
    "image_paths = list(Path(image_folder).rglob(\"*.jpg\"))\n",
    "\n",
    "# =============== Transformationen vorbereiten ===============\n",
    "to_tensor = T.ToTensor()\n",
    "resize_224 = {\n",
    "    \"bicubic\": T.Resize((224, 224), interpolation=Image.BICUBIC),\n",
    "    \"bilinear\": T.Resize((224, 224), interpolation=Image.BILINEAR),\n",
    "    \"nearest\": T.Resize((224, 224), interpolation=Image.NEAREST)\n",
    "}\n",
    "\n",
    "# =============== Methoden ===============\n",
    "def method_bicubic(img): return resize_224[\"bicubic\"](img)\n",
    "def method_bilinear(img): return resize_224[\"bilinear\"](img)\n",
    "def method_nearest(img): return resize_224[\"nearest\"](img)\n",
    "\n",
    "def method_stride(img_tensor):\n",
    "    cropped = center_crop_to_square_multiple(img_tensor, multiple=224)\n",
    "    if cropped is None:\n",
    "        return None\n",
    "    factor = cropped.shape[1] // 224\n",
    "    return cropped[:, ::factor, ::factor]\n",
    "\n",
    "def center_crop_to_square_multiple(img_tensor, multiple=224):\n",
    "    _, h, w = img_tensor.shape\n",
    "    min_dim = min(h, w)\n",
    "    target_size = (min_dim // multiple) * multiple\n",
    "    if target_size < multiple:\n",
    "        return None\n",
    "    top = (h - target_size) // 2\n",
    "    left = (w - target_size) // 2\n",
    "    return img_tensor[:, top:top+target_size, left:left+target_size]\n",
    "\n",
    "def to_numpy(img):\n",
    "    if isinstance(img, Image.Image):\n",
    "        img = np.array(img)\n",
    "    elif isinstance(img, torch.Tensor):\n",
    "        img = img.detach().cpu()\n",
    "        if img.max() <= 1.0:\n",
    "            img = img * 255\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "def compare_metrics(ref, other):\n",
    "    return psnr(ref, other), ssim(ref, other, channel_axis=-1)\n",
    "\n",
    "# =============== Metrik-Tracking ===============\n",
    "times = {\"bicubic\": [], \"bilinear\": [], \"stride\": [], \"nearest\": []}\n",
    "psnr_list = {\"bilinear\": [], \"stride\": [], \"nearest\": []}\n",
    "ssim_list = {\"bilinear\": [], \"stride\": [], \"nearest\": []}\n",
    "\n",
    "# =============== Verarbeitungsschleife ===============\n",
    "print(f\"Starte Verarbeitung von {len(image_paths)} Bildern...\\n\")\n",
    "for path in tqdm(image_paths):\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img_tensor = to_tensor(img)\n",
    "\n",
    "        # Methode 1 – Bicubic (Referenz)\n",
    "        t0 = time.time()\n",
    "        ref_out = method_bicubic(img)\n",
    "        t1 = time.time()\n",
    "        times[\"bicubic\"].append((t1 - t0) * 1000)\n",
    "        ref_np = to_numpy(ref_out)\n",
    "\n",
    "        # Methode 2 – Bilinear\n",
    "        t0 = time.time()\n",
    "        out_bil = method_bilinear(img)\n",
    "        t1 = time.time()\n",
    "        times[\"bilinear\"].append((t1 - t0) * 1000)\n",
    "        psnr_val, ssim_val = compare_metrics(ref_np, to_numpy(out_bil))\n",
    "        psnr_list[\"bilinear\"].append(psnr_val)\n",
    "        ssim_list[\"bilinear\"].append(ssim_val)\n",
    "\n",
    "        # Methode 3 – Stride\n",
    "        t0 = time.time()\n",
    "        out_stride = method_stride(img_tensor)\n",
    "        t1 = time.time()\n",
    "        if out_stride is None:\n",
    "            print(f\"Bild {path.name} zu klein für Stride.\")\n",
    "            continue\n",
    "        times[\"stride\"].append((t1 - t0) * 1000)\n",
    "        psnr_val, ssim_val = compare_metrics(ref_np, to_numpy(out_stride))\n",
    "        psnr_list[\"stride\"].append(psnr_val)\n",
    "        ssim_list[\"stride\"].append(ssim_val)\n",
    "\n",
    "        # Methode 4 – Nearest\n",
    "        t0 = time.time()\n",
    "        out_near = method_nearest(img)\n",
    "        t1 = time.time()\n",
    "        times[\"nearest\"].append((t1 - t0) * 1000)\n",
    "        psnr_val, ssim_val = compare_metrics(ref_np, to_numpy(out_near))\n",
    "        psnr_list[\"nearest\"].append(psnr_val)\n",
    "        ssim_list[\"nearest\"].append(ssim_val)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {path}: {e}\")\n",
    "\n",
    "# =============== Ergebnisse ausgeben ===============\n",
    "def summarize(name, values):\n",
    "    values = np.array(values)\n",
    "    return f\"{name:<15}: Mittelwert = {values.mean():.4f}, Std = {values.std():.4f}\"\n",
    "\n",
    "print(\"\\n--- Benchmark-Ergebnisse ---\")\n",
    "for key in times:\n",
    "    print(summarize(f\"Zeit {key}\", times[key]))\n",
    "\n",
    "print()\n",
    "for key in psnr_list:\n",
    "    print(summarize(f\"PSNR {key}\", psnr_list[key]))\n",
    "    print(summarize(f\"SSIM {key}\", ssim_list[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206cefe6",
   "metadata": {},
   "source": [
    "### Benchmark-Ergebnisse\n",
    "Bicubic resized images were taken as benchmark results and the resized versions of the other interpolation techniques are compared via SSIM and PSNR with the bicubic result\n",
    "\n",
    "| Methode   | Zeit (Mittelwert) | Zeit (Std) | PSNR (Mittelwert) | PSNR (Std) | SSIM (Mittelwert) | SSIM (Std) |\n",
    "|-----------|-------------------|------------|-------------------|------------|-------------------|------------|\n",
    "| bicubic   | 2.7382            | 2.3283     | -                 | –          | –                 | –          |   \n",
    "| bilinear  | 1.3936            | 1.2276     | 50.8343           | 2.2208     | 0.9966            | 0.0008     |\n",
    "| stride    | 0.0558            | 0.2297     | 19.9579           | 5.8874     | 0.5692            | 0.1375     |\n",
    "| nearest   | 0.1169            | 0.3198     | 40.9852           | 2.3799     | 0.9675            | 0.0157     |\n",
    "\n",
    "\n",
    "- Stride is much faster than the other two but results large differences in terms of pixel values (psnr) and also large losses in terms of structural similarity (meaning the visible noise and loss of structural informations that a human would also be able to see)\n",
    "- Nearest Interpolation results in nearly the same loss then Bilinear Interpolation meaning that the images tend to have few texture, are mainly centered and have no hard lines or edge which the nearest interpolation would distort. Therefor for our image dataset the nearest interpolation technique seems the by the best traid of in terms of speed and interpolation accuracy. The results of the model have to tested after the hyperparameters are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c820e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HTCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
